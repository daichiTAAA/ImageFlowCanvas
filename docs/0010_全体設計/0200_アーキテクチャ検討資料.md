# アーキテクチャ検討

## **第1章：動的クラウドネイティブパイプラインのアーキテクチャ設計**

### **1.1. 中核となる課題と戦略的解決策**

本プロジェクトが解決すべき中核的な課題は、「Web画面から、前処理、AI処理、後処理といった『部品』を自由に組み合わせ、動的なパイプラインを構築したい」という高度な要求にあります。この要件は、単にコンテナを実行するだけでなく、コンテナ間の依存関係、実行順序、データフローを柔軟かつ動的に制御できるアーキテクチャを必要とします。さらに、将来的なカメラ台数の増減や処理負荷の変動に対応できるスケーラビリティ、そして特定のクラウドベンダーにロックインされないポータビリティも重要な考慮事項です。  
これらの課題に対する結論として推奨されるアーキテクチャは、以下のコンポーネントを組み合わせたマイクロサービスベースのシステムです。

1. **コンテナオーケストレーション基盤 (K3s):** 軽量でありながら完全な互換性を持つKubernetesディストリビューション。コンテナ化されたマイクロサービスのライフサイクル管理（デプロイ、スケーリング、自己修復）を担う、システム全体の土台となります。  
2. **ワークフローエンジン (Argo Workflows):** パイプラインの「指揮者」。ユーザーが定義した複雑な処理フローを解釈し、K3s上で適切な処理コンテナを適切な順序で起動・監視します。動的パイプライン実現の核心です。  
3. **共有オブジェクトストレージ (MinIO):** パイプラインの各ステップ間で、画像のような大きなデータを受け渡すための中間ストレージ。ネットワーク負荷を最小限に抑え、各処理コンポーネントを疎結合に保ちます。  
4. **マイクロサービス化された処理コンテナ:** 「リサイズ処理」や「物体検出AI」といった各機能を、それぞれ独立したコンテナとして開発します。これにより、システムの柔軟性、拡張性、メンテナンス性が飛躍的に向上します。

このアーキテクチャは、初期の学習コストを上回る、長期的な運用における絶大なメリットを提供します。続くセクションでは、なぜこの技術スタックが最適であるか、その論理的な根拠を詳細に解説します。

### **1.2. アーキテクチャの正当性 I：オーケストレーション層 (K3s vs. Nomad)**

コンテナオーケストレーション基盤の選定は、システム全体の方向性を決定する重要な選択です。ここでは、軽量KubernetesであるK3sと、HashiCorp社のNomadを比較し、なぜ本プロジェクトにおいてK3sが最適であるかを論証します。  
選択の核心は、単なる機能の優劣ではなく、プロジェクトの最重要要件である「動的パイプライン」を最も効率的かつ強力に実現できるエコシステムはどちらか、という点にあります。この観点から、Argo Workflowsとのネイティブな親和性を持つK3sが明確な優位性を持ちます。  
Argo Workflowsは、KubernetesのAPIやリソース（Pod, ServiceAccount, Custom Resource Definitionsなど）を深く利用して、パイプラインの各ステップを精緻に制御するように設計されています。K3sは、軽量でありながら100% Kubernetes互換のAPIを提供するため、Argo Workflowsの能力を最大限に引き出すことが可能です。このシームレスな連携こそが、K3sを選択する決定的な理由です。  
Nomadも非常に優れたスケジューラですが、Argo Workflowsのような高度なワークフローエンジンを同等の手軽さと機能性で連携させることは困難です。結果として、自前で多くの制御ロジックを実装する必要が生じ、開発・運用コストが増大するリスクを伴います。  
さらに、K3s（Kubernetes）を選択することは、Cloud Native Computing Foundation (CNCF) が育んできた広大で成熟したエコシステムへのアクセスを意味します。将来的に監視（Prometheus）、ロギング（Fluentd）、サービスメッシュ（Istio）といった高度な運用要件が発生した際、Kubernetes上で動作することを前提に開発された無数のツール群を容易に導入できます。これは、長期的なシステムの拡張性と運用安定性において、計り知れない価値をもたらします。  
**表1: オーケストレータ比較：K3s vs. Nomad**

| 評価項目                 | k3s (Kubernetes)                                                                                                              | Nomad (HashiCorp)                                                                                                         | 本プロジェクトへの影響と結論                                                                            |
| :----------------------- | :---------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------ |
| **哲学・スコープ**       | コンテナ中心。コンテナ化されたアプリケーションのデプロイ、スケーリング、管理に特化。業界標準のエコシステムを形成。            | 汎用ワークロード。コンテナだけでなく、VM、スタンドアロンアプリも同様に扱える。シンプルさと柔軟性を重視。                  | 要件はコンテナ処理が中心のため、k3sの専門性が活きる。                                                   |
| **ワークフロー制御**     | ◎ **圧倒的に優位**。Argo WorkflowsやTektonなど、高度で成熟したパイプラインツールがネイティブに連携。Pod単位でステップを実行。 | △ 限定的。Nomad自身の機能やサードパーティツールで対応するが、Argo Workflowsほどの機能性と成熟度を持つ選択肢は少ない。     | 「動的なパイプライン」という核心要件において、Argo Workflowsを最大限活用できるk3sが決定的な強みを持つ。 |
| **エコシステム**         | ◎ **決定的利点**。CNCFの多数のプロジェクトがネイティブに連携。監視、ロギング、セキュリティなど、あらゆるツールが揃う。        | ○ HashiCorp製品群とは強力に連携。しかし、サードパーティ製ツール、特にワークフローエンジンの選択肢は限定的。               | 将来的なシステムの拡張性と運用高度化を見据えた場合、k3sの広大なエコシステムは絶大なメリットとなる。     |
| **アーキテクチャ**       | Kubernetesの主要コンポーネントを単一バイナリに集約。軽量だが、Pod, Service等のKubernetes概念はそのまま。                      | さらにシンプル。単一バイナリでサーバーとクライアントを兼ねる。ただし、周辺機能は他ツール（Consul, Vault）との連携が前提。 | 導入の容易さではNomadに分があるが、k3sも十分にシンプル化されており、機能の網羅性で勝る。                |
| **サービスディスカバリ** | ◎ 組み込み。Serviceリソースと内部DNSによる強力で成熟した機能が標準で提供される。                                              | △ 外部連携必須。Consulとの連携が事実上必須。連携はスムーズだが、管理コンポーネントが増える。                              | k3sは単体で完結しているため、構成がよりシンプルになる。                                                 |

### **1.3. アーキテクチャの正当性 II：設計パターン (マイクロサービス vs. モノリス)**

次に、アプリケーション自体の設計パターンを比較検討します。具体的には、各処理を独立したコンテナとして構築する「マイクロサービス」アプローチと、全ての処理ロジックを一つの巨大なコンテナに詰め込む「単一コンテナ＋ストラテジーパターン」アプローチです。  
結論から言えば、本プロジェクトの要件である「部品の自由な組み合わせ」を実現するためには、マイクロサービスアーキテクチャが唯一の現実的な選択肢です。  
一見すると、「単一コンテナ」アプローチは管理するコンテナイメージが1つで済むため、シンプルに見えるかもしれません。しかし、その内部には、システムの成長と共に必ず顕在化する、致命的ないくつかの「隠れたコスト」を内包しています。

1. **依存関係の地獄 (Dependency Hell):** 最大の問題点です。新しいAIモデルを追加しようとした際、そのモデルが必要とするライブラリ（例: 特定バージョンのPyTorchやCUDA）が、既存の別のモデルが要求するライブラリと競合する可能性があります。例えば、ある処理はopencv-python-headlessを、別の処理はGUI機能を含むopencv-pythonを必要とするかもしれません。これら全てを単一の環境に同居させることは、極めて困難であり、ビルドの失敗や実行時エラーの温床となります。マイクロサービスアーキテクチャでは、各コンテナが自身のDockerfileで独立した環境を持つため、この問題は原理的に発生しません。  
2. **リソース効率の極端な悪化:** パイプラインがCPUしか使用しない単純なリサイズ処理のみで構成される場合でも、モノリスコンテナはGPUで動作するAIモデルのライブラリを含んでいるため、高価なGPU搭載インスタンス上で実行せざるを得なくなります。これは甚だしいリソースの無駄遣いです。マイクロサービスであれば、AI処理コンテナだけをGPUインスタンスで実行し、他のCPU処理は安価なインスタンスで動かすといった、適材適所の効率的なリソース割り当てが可能です。  
3. **低い耐障害性:** あるAIモデルのバグがメモリリークを引き起こした場合、モノリスコンテナのプロセス全体がクラッシュし、そのコンテナで実行されている全く無関係な他のパイプラインも全て停止してしまいます。マイクロサービスでは、障害の影響はそのコンテナ（Pod）内に完全に閉じ込められ、Argo Workflowsがリトライ処理を行うなど、システム全体への影響を最小限に抑えることができます。

これらの理由から、「単一コンテナ」アプローチは、将来的な拡張性や保守性を著しく損なう、リスクの高い選択と言えます。  
**表2: アーキテクチャパターン比較：マイクロサービス vs. モノリス**

| 評価項目           | アプローチ2：マイクロサービス (推奨)                                                                                                   | アプローチ1：単一コンテナ \+ ストラテジー                                                                                                 |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------- |
| **柔軟性・拡張性** | ◎ **非常に高い**。独立した新しいコンテナを作成するだけで、既存のどのコンポーネントにも影響を与えずに機能追加が可能。                   | × **非常に低い**。新しいロジックとライブラリを巨大なコンテナに追加し、既存機能への影響をすべてテストする必要がある。非常にリスキー。      |
| **依存関係管理**   | ◎ **容易**。各コンテナは自身が必要なライブラリだけを管理すれば良い。バージョン競合は原理的に発生しない。                               | × **破綻寸前**。全処理のライブラリを同居させる必要があり、バージョン競合のリスクが極めて高い（例: TensorFlowとPyTorchのCUDA要件の違い）。 |
| **リソース効率**   | ◎ **非常に良い**。AI処理コンテナだけをGPUインスタンスで実行するなど、適材適所の割り当てが可能。コスト効率に優れる。                    | × **非常に悪い**。CPUしか使わないパイプラインでも、高価なGPUインスタンスで実行する必要がある。リソースの無駄遣い。                        |
| **耐障害性**       | ◎ **高い**。あるコンテナの障害は、そのコンテナ内に閉じる。ワークフローエンジンが適切にエラー処理を行い、他への影響を最小限に抑える。   | × **低い**。ある処理のバグがプロセス全体をクラッシュさせ、無関係なパイプラインもすべて停止するリスクがある。                              |
| **スループット**   | ◎ **優れる**。ボトルネックになっている処理（例: AI処理）のコンテナだけを増やすことで、パイプライン全体の処理能力を効率的に向上できる。 | △ **劣る**。パイプライン全体を一つの単位としてしかスケールできず、ボトルネック箇所だけの増強ができない。                                  |

### **1.4. 人間的要素への配慮：学習コストを戦略的投資へ**

Docker Composeの経験はあってもKubernetesが未経験の組織にとって、K3sの導入に伴う学習コストが懸念されるのは当然です。しかし、この初期コストは乗り越え不可能な障壁ではなく、プロジェクトの核心的要件を満たし、組織の技術力を長期的に向上させるための「戦略的投資」と捉えるべきです。  
K3sを推奨する最大の理由は、それが「動的なパイプライン」という要件を実現するための、最も現実的で堅牢な手段だからです。この要件を満たすにはArgo Workflowsのような「指揮者」が不可欠であり、その指揮者はKubernetesという舞台で最高のパフォーマンスを発揮します。  
この学習コストという投資に対して、K3sはいくつかの緩和策を提供します。

* **学習の集中:** K3sは、フル機能のKubernetesを単一の軽量バイナリで提供します。インストールや初期設定が劇的に簡素化されているため、開発者はetcdの管理のような複雑な運用タスクから解放され、Pod、Service、DeploymentといったKubernetesの普遍的なコア概念の学習に集中できます。  
* **スモールスタート:** K3sは、VM2台といった小規模なリソースでも安定して動作するように設計されています。これにより、最初から大規模なクラスタを準備する必要なく、スモールスタートで実践的な経験を積みながら、徐々に運用をスケールさせていくことが可能です。  
* **豊富な情報源:** Kubernetesはコンテナ技術の事実上の業界標準であるため、公式ドキュメント、ブログ、フォーラム、チュートリアルなど、学習資料や問題解決のための情報がオンライン上に無数に存在します。これは、学習過程で発生するであろう疑問や問題を解決する上で大きな助けとなります。

短期的な学習コストを惜しんで安易なアーキテクチャ（例：単一コンテナ）を選択した場合、前述の「依存関係の地獄」や「非効率なリソース利用」といった、より深刻で解決困難な「隠れた技術的負債」が将来的に発生します。初期の学習コストを未来への投資と捉え、K3sを導入することは、これらの将来的なリスクを回避し、プロジェクトを長期的な成功に導くための最も合理的で堅牢な選択肢なのです。

## **第2章：基盤構築 \- K3sクラスタのプロビジョニングと管理**

この章では、動的パイプラインの実行基盤となるK3sクラスタを構築し、日常的な運用に不可欠な基本操作を習得するための具体的な手順を解説します。

### **2.1. K3s詳解：シンプルさの源泉**

K3sが「軽量」である理由は、いくつかの賢い設計上の工夫によるものです。これらを理解することは、K3sを自信を持って運用する上で役立ちます。

* **コンポーネントの集約:** 通常のKubernetesでは、kube-apiserver、kube-scheduler、kube-controller-managerといった複数の管理コンポーネントが別々のプロセスとして動作します。K3sは、これらの機能を単一のバイナリにまとめ、一つのプロセスとして実行します。これにより、プロセス間通信のオーバーヘッドが削減され、メモリ使用量が大幅に低減されます。  
* **データベースの置換:** Kubernetesはクラスタの状態を保存するために、分散Key-Valueストアであるetcdを必要とします。etcdは強力ですが、設定が複雑でリソース消費も大きいという側面があります。K3sは、デフォルトでこのetcdを、軽量な組み込みSQLデータベースであるSQLiteに置き換えています。これにより、外部依存なく、単一のバイナリだけで高速にクラスタを起動できます。  
* **軽量なコンテナランタイム:** Dockerの代わりに、より軽量でコア機能に特化したコンテナランタイムであるcontainerdを直接利用します。  
* **不要な機能の削減:** レガシーな機能や、特定のクラウドプロバイダー（AWS, GCPなど）に依存するドライバー（インツリードライバー）を本体から削除しています。必要な機能はアドオンとして後から追加できるため、デフォルトの状態が非常にスリムになっています。

これらの工夫により、K3sはKubernetesとの完全なAPI互換性を保ちながら、小規模な環境でも快適に動作する軽量性と、驚くほどの導入の手軽さを実現しています。

### **2.2. ステップ・バイ・ステップ インストールガイド**

K3sのインストールは非常にシンプルです。パイプライン実行サーバーとなるVM（VM2）にSSHでログインし、以下の手順を実行します。  
**1\. K3sのインストール**  
公式のインストールスクリプトをダウンロードし、実行します。  
# K3sをダウンロードし、インストールして、systemdサービスとして起動します  
curl -sfL https://get.k3s.io | sh -

この一行のコマンドが、K3sのバイナリをダウンロードし、サーバー（マスター）ノードとして設定し、systemdのサービスとして登録・起動するまでを自動的に行います。  
**2\. kubectlの接続設定**  
K3sサーバーをインストールすると、クラスタを操作するための設定ファイルが/etc/rancher/k3s/k3s.yamlに自動生成されます。Kubernetesの標準コマンドラインツールであるkubectlがこのファイルを読み込めるように、ホームディレクトリにコピーして所有者を変更します。  
# 設定ファイルを~/.kubeディレクトリにコピー  
```
sudo mkdir -p ~/.kube  
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
```
# ファイルの所有者を現在のユーザーに変更  
```
sudo chown $(id -u):$(id -g) ~/.kube/config
```
# 環境変数を設定（任意ですが推奨）  
```
export KUBECONFIG=~/.kube/config  
echo 'export KUBECONFIG=~/.kube/config' >> ~/.bashrc
```
これらのコマンドにより、ターミナルから直接kubectlコマンドを実行して、構築したK3sクラスタを操作できるようになります。

### **2.3. クラスタの検証と日常的な運用**

インストールが完了したら、クラスタが正常に稼働していることを確認します。  
# クラスタに参加しているノードの一覧を表示します  
```
kubectl get nodes
```

以下のような出力が表示され、STATUSがReadyとなっていれば、K3sクラスタは正常にプロビジョニングされています。
```
NAME   STATUS   ROLES                  AGE   VERSION  
vm2    Ready    control-plane,master   5m    v1.28.9+k3s1
```
K3sのサービス自体の管理（起動、停止、状態確認など）は、systemdを通じて行います。  
# K3sサーバーサービスの状態を確認  
```
sudo systemctl status k3s
```
# K3sサーバーサービスを再起動  
```
sudo systemctl restart k3s
```
# K3sサーバーサービスを停止  
```
sudo systemctl stop k3s
```
### **2.4. kubectl 基本コマンドリファレンス**

kubectlは、Kubernetesクラスタと対話するための最も重要なツールです。Kubernetesに不慣れなチームにとって、以下の基本コマンドを習得することが、開発と運用の効率を上げる鍵となります。  
**表3: 必須kubectlコマンドリファレンス**

| カテゴリ                         | コマンド                                       | 説明と使用例                                                                                                                                                                             |
| :------------------------------- | :--------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **リソースの確認 (Inspection)**  | kubectl get \<resource\>                       | 指定した種類のリソースを一覧表示します。最も頻繁に使うコマンドです。\<br\>**例:** kubectl get pods, kubectl get services, kubectl get deployments                                        |
|                                  | kubectl get all \-A                            | **全てのNamespace**における**全ての主要リソース**を一覧表示します。クラスタ全体の状況を俯瞰するのに非常に便利です。                                                                      |
|                                  | kubectl describe \<resource\> \<name\>         | **問題解決の第一歩**。リソースの詳細情報（現在の状態、設定、イベントログなど）を表示します。Podが起動しない時など、原因調査に不可欠です。\<br\>**例:** kubectl describe pod my-pod-12345 |
|                                  | kubectl get \<resource\> \<name\> \-o yaml     | リソースの現在の定義をYAML形式で表示します。クラスタ上で実際にどう設定されているかを確認するのに役立ちます。\<br\>**例:** kubectl get deployment my-app \-o yaml                         |
| **リソースの操作 (Interaction)** | kubectl apply \-f \<filename.yaml\>            | YAMLファイルに定義されたリソースを作成または更新します。「宣言的」な管理の基本です。\<br\>**例:** kubectl apply \-f my-app.yaml                                                          |
|                                  | kubectl delete \-f \<filename.yaml\>           | YAMLファイルに定義されたリソースを削除します。\<br\>**例:** kubectl delete \-f my-app.yaml                                                                                               |
|                                  | kubectl delete \<resource\> \<name\>           | 特定のリソースを名前で指定して削除します。\<br\>**例:** kubectl delete pod my-pod-12345                                                                                                  |
| **デバッグ (Debugging)**         | kubectl logs \<pod-name\>                      | Pod内のコンテナの標準出力を表示します。アプリケーションのログを確認する基本コマンドです。                                                                                                |
|                                  | kubectl logs \-f \<pod-name\>                  | ログをリアルタイムでストリーミング表示します（tail \-fと同様）。デバッグ中に非常に便利です。                                                                                             |
|                                  | kubectl exec \-it \<pod-name\> \-- \<command\> | 実行中のPodのコンテナ内でコマンドを実行します。コンテナの中に入って調査する際に必須です。\<br\>**例:** kubectl exec \-it my-pod-12345 \-- /bin/bash                                      |
| **Namespace関連**                | kubectl get pods \-n \<namespace\>             | 指定したNamespace内のPodを一覧表示します。Argo Workflowsなど、特定のNamespaceで動くコンポーネントを確認する際に使用します。\<br\>**例:** kubectl get pods \-n argo                       |

特にkubectl describeは、"なぜかPodが起動しない"、"Serviceにアクセスできない"といった問題に直面した際に、その原因を示すイベントログ（例：ImagePullBackOff, CrashLoopBackOff）が表示されるため、最初に実行すべきコマンドです。

## **第3章：コアサービスのデプロイ**

K3sクラスタという土台の上に、パイプラインの実行に不可欠な2つのコアサービス、「共有ストレージ（MinIO）」と「ワークフローエンジン（Argo Workflows）」をデプロイします。

### **3.1. MinIOのデプロイ：パイプラインの共有ストレージ**

パイプラインの各ステップ（コンテナ）は独立していますが、処理対象の画像データや処理結果の画像を互いに受け渡す必要があります。巨大な画像データをコンテナ間で直接送受信するのは非効率であり、ネットワーク帯域を圧迫します。そこで、Amazon S3互換のAPIを持つオープンソースのオブジェクトストレージであるMinIOをクラスタ内にデプロイし、全コンテナがアクセスできる共有ストレージとして利用します。

#### **3.1.1. 永続的ストレージの準備 (Persistent Volume)**

コンテナ内のデータは、コンテナが再起動すると消えてしまいます。MinIOに保存した画像データを永続化するため、KubernetesのPersistentVolume (PV) と PersistentVolumeClaim (PVC) という仕組みを利用します。これは、ホストマシンの特定のディレクトリを、コンテナが利用できる永続的なストレージ領域としてマウントする機能です。  
まず、ホストマシン（VM2）上にデータを保存するためのディレクトリを作成します。  
sudo mkdir -p /data/minio

次に、このディレクトリを指すPersistentVolumeと、MinIOがそのボリュームを要求するためのPersistentVolumeClaimを定義したYAMLファイルを作成します。  
**minio-pv-pvc.yaml**  
```
apiVersion: v1  
kind: PersistentVolume  
metadata:  
  name: minio-pv  
  labels:  
    type: local  
spec:  
  storageClassName: manual  
  capacity:  
    storage: 10Gi # 必要に応じてサイズを調整  
  accessModes:  
    - ReadWriteOnce  
  hostPath:  
    path: "/data/minio" # ホスト上のディレクトリを指定  
---  
apiVersion: v1  
kind: PersistentVolumeClaim  
metadata:  
  name: minio-pvc  
spec:  
  storageClassName: manual  
  accessModes:  
    - ReadWriteOnce  
  resources:  
    requests:  
      storage: 10Gi # PVと同じかそれ以下のサイズを要求
```
このYAMLファイルをクラスタに適用します。  
```
kubectl apply -f minio-pv-pvc.yaml
```
#### **3.1.2. MinIOのDeploymentとServiceの定義**

次に、MinIOコンテナ自体をデプロイします。以下のYAMLは、MinIOのDeployment（どういうコンテナを起動するか）とService（クラスタ内外からどうアクセスするか）を定義します。  
**minio-deployment.yaml**  
```
apiVersion: apps/v1  
kind: Deployment  
metadata:  
  name: minio  
spec:  
  selector:  
    matchLabels:  
      app: minio  
  strategy:  
    type: Recreate # シンプルな再作成戦略  
  template:  
    metadata:  
      labels:  
        app: minio  
    spec:  
      # 作成したPersistentVolumeClaimをこのPodにマウントする  
      volumes:  
      - name: storage  
        persistentVolumeClaim:  
          claimName: minio-pvc  
      containers:  
      - name: minio  
        image: minio/minio:RELEASE.2023-09-04T19-57-37Z # 安定したバージョンを推奨  
        args:  
        - server  
        - /data  
        - --console-address  
        - ":9001"  
        env:  
        # 本番環境ではKubernetes Secretを使用することを強く推奨  
        - name: MINIO_ROOT_USER  
          value: "minioadmin"  
        - name: MINIO_ROOT_PASSWORD  
          value: "minioadmin"  
        ports:  
        - containerPort: 9000 # S3 APIポート  
          name: api  
        - containerPort: 9001 # Web UIポート  
          name: console  
        # マウントしたボリュームをコンテナ内の/dataディレクトリに割り当てる  
        volumeMounts:  
        - name: storage  
          mountPath: /data  
---  
apiVersion: v1  
kind: Service  
metadata:  
  name: minio-service  
spec:  
  selector:  
    app: minio # このラベルを持つPodにトラフィックを転送  
  ports:  
    - name: api  
      protocol: TCP  
      port: 9000  
      targetPort: 9000  
    - name: console  
      protocol: TCP  
      port: 9001  
      targetPort: 9001  
  # クラスタ外部からアクセスするためにNodePortタイプを使用  
  type: NodePort
```
このYAMLでは、先ほど作成したminio-pvcをコンテナの/dataディレクトリにマウントしています。これにより、MinIOにアップロードされたデータはホストの/data/minioディレクトリに保存され、Podが再起動してもデータが失われることはありません。  
このファイルをクラスタに適用します。  
kubectl apply -f minio-deployment.yaml

#### **3.1.3. MinIO UIへのアクセスとバケット作成**

NodePortサービスにより、VM2のIPアドレスと特定のポート番号でMinIOのWeb UIにアクセスできます。ポート番号は以下のコマンドで確認します。  
kubectl get service minio-service

出力例：  
```
NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE  
minio-service   NodePort   10.43.147.200   <none>        9000:30090/TCP,9001:30091/TCP   1m
```
この例では、9001番ポートがホストの30091番ポートにマッピングされています。ブラウザで http://\<VM2のIPアドレス\>:30091 にアクセスし、YAMLで設定したユーザー名（minioadmin）とパスワード（minioadmin）でログインします。  
ログイン後、パイプラインで使用するバケットを3つ作成しておきます。

* raw: 処理前の元画像を保存するバケット  
* processed: 処理後の画像を保存するバケット  
* argo-artifacts: Argo Workflowsが中間ファイルやログを保存するためのバケット

### **3.2. Argo Workflowsのデプロイ：パイプラインの指揮者**

次に、パイプラインの実行を司る「指揮者」、Argo Workflowsをインストールします。

#### **3.2.1. Namespaceの作成と公式マニフェストの適用**

Argo関連のリソースをまとめて管理するために、専用のargoというNamespace（区画）を作成します。  
kubectl create namespace argo

公式ドキュメントで提供されているインストール用マニフェストを適用します。これにより、Argo Workflowsの動作に必要な全てのコンポーネント（Argo Server, Workflow Controllerなど）と、それらに必要な権限設定（ServiceAccount, Roleなど）が一括でデプロイされます。  
# クラスタ全体でArgoが動作するための権限設定などを含むマニフェストを適用  
```
kubectl apply -n argo -f https://github.com/argoproj/argo-workflows/releases/download/v3.5.5/install.yaml
```
#### **3.2.2. Argo WorkflowsとMinIOの連携設定**

Argo Workflowsが、アーティファクト（処理中の画像など）の保存場所として先ほどデプロイしたMinIOを認識できるように設定する必要があります。この設定は、KubernetesのSecret（機密情報用）とConfigMap（設定情報用）を用いて行います。  
まず、MinIOのアクセスキーとシークレットキーを保持するSecretを作成します。  
**minio-secret.yaml**  
```
apiVersion: v1  
kind: Secret  
metadata:  
  name: my-minio-secret  
  namespace: argo # Argoがアクセスできるようargo Namespaceに作成  
type: Opaque  
stringData:  
  accesskey: minioadmin  
  secretkey: minioadmin
```
次に、MinIOのエンドポイント情報と、使用するSecretの名前を定義したConfigMapを作成します。  
**argo-artifact-repo-config.yaml**  
```
apiVersion: v1  
kind: ConfigMap  
metadata:  
  name: argo-artifact-repository-config  
  namespace: argo  
data:  
  # 'minio'というキーでS3互換ストレージの設定を定義  
  minio: |  
    s3:  
      # Argoが中間ファイルなどを保存するデフォルトバケット  
      bucket: argo-artifacts  
      # K3sクラスタ内部からMinIOにアクセスするためのDNS名  
      # フォーマット: <service-name>.<namespace>.svc.cluster.local:<port>  
      endpoint: minio-service.default.svc.cluster.local:9000  
      # 上で作成したSecretを参照  
      accessKeySecret:  
        name: my-minio-secret  
        key: accesskey  
      secretKeySecret:  
        name: my-minio-secret  
        key: secretkey  
      # 自己署名証明書など、セキュアでない接続を許可  
      insecure: true
```
ここで重要なのはendpointのminio-service.default.svc.cluster.local:9000という値です。これはKubernetesが内部で提供するDNSサービスの仕組みであり、argo Namespaceで実行されているArgoのコンポーネントが、default Namespaceで実行されているminio-serviceという名前のServiceに、クラスタ内ネットワークを通じてアクセスすることを可能にします。この仕組みを理解することが、マイクロサービス間の連携をデバッグする上で非常に重要です。  
これらのYAMLファイルをクラスタに適用します。
```  
kubectl apply -f minio-secret.yaml  
kubectl apply -f argo-artifact-repo-config.yaml
```
### **3.3. Argo UIへのアクセス**

Argo Workflowsは、パイプラインの実行状況をリアルタイムで可視化できる強力なWeb UIを提供します。ローカルマシンからこのUIに安全にアクセスするため、kubectl port-forwardコマンドを使用します。  
# ローカルPCの2746番ポートへのアクセスを、argo Namespaceのargo-server Podの2746番ポートに転送する  
```
kubectl -n argo port-forward deployment/argo-server 2746:2746
```
このコマンドを実行したままの状態で、Webブラウザで https://localhost:2746 にアクセスします。自己署名証明書に関する警告が表示されますが、これは正常な動作なので、無視して進んでください。Argo Workflowsのダッシュボードが表示されれば、コアサービスのデプロイは完了です。

## **第4章：Argo Workflowsによる動的パイプラインの習得**

この章では、Argo Workflowsのコア概念を深く理解し、「部品を自由に組み合わせる」という要件を実現するためのパイプライン定義方法を習得します。

### **4.1. Workflowの構造：パイプラインの解剖学**

Argo Workflowsにおける全ての処理は、WorkflowというKubernetesのカスタムリソース（CRD）をYAML形式で定義することによって実行されます。このYAMLを構成する主要な概念は以下の通りです。

* **Workflow:** パイプライン全体の定義そのものです。ワークフローの名前、実行を開始するエントリーポイント（entrypoint）、そして後述するテンプレート（templates）の集合で構成されます。これがArgoに実行依頼する基本単位となります。  
* **Template:** ワークフローにおける「再利用可能な処理単位」を定義する、最も重要な要素です。様々な種類のテンプレートが存在します。  
* **Parameters:** ワークフローやテンプレートに外部から値を渡すための仕組みです。inputs（入力）とoutputs（出力）があり、{{...}}という構文を使って値にアクセスします。ステップ間のデータ連携は、このパラメータを通じて行われます。  
* **Artifacts:** パイプラインのステップ間で受け渡される「ファイル」（画像、モデル、ログなど）を指します。Argoは、MinIOのようなアーティファクトリポジトリと連携し、ファイルのアップロード・ダウンロードを抽象化してくれます。

### **4.2. パイプラインロジックの定義：適切なテンプレートの選択**

Argo Workflowsは、パイプラインのロジックを表現するために、いくつかの強力なテンプレートタイプを提供します。実現したいフローに応じて適切なテンプレートを選択することが、効率的なパイプライン設計の鍵となります。  
**表4: Argo Workflow テンプレートタイプの比較**

| テンプレートタイプ         | 主な用途                       | 特徴とユースケース                                                                                                                                                                                                                      |
| :------------------------- | :----------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **container**              | **基本的な処理の実行**         | 最も基本的なテンプレート。特定のDockerイメージを指定し、コマンドと引数を渡して実行します。「リサイズ処理コンテナ」や「物体検出AIコンテナ」など、個々のマイクロサービスを実行するために使用します。                                      |
| **dag (有向非巡回グラフ)** | **複雑な依存関係を持つフロー** | **動的パイプライン実現の核心**。複数のタスク（tasks）と、それらの依存関係（dependencies）を定義できます。「タスクAが完了したらタスクBとCを並列実行し、両方が完了したらタスクDを実行する」といった複雑な処理フローを自由に構築できます。 |
| **steps**                  | **単純な逐次実行フロー**       | dagよりもシンプルな、上から下への逐次実行フローを定義します。各ステップが順番に実行されるだけでよい、単純な直列処理に適しています。                                                                                                     |
| **script**                 | **軽量なスクリプトの実行**     | PythonやJavaScriptなどの短いスクリプトを直接YAML内に記述して実行できます。簡単なデータ変換や条件分岐など、わざわざコンテナイメージを作成するまでもない軽量な処理に便利です。                                                            |

本プロジェクトの「部品を自由に組み合わせる」という要件には、dagテンプレートが最も適しています。Web UIからユーザーが選択した部品の組み合わせと順序に基づき、バックエンドで動的にdagテンプレートのtasksとdependenciesを生成することで、あらゆるパイプラインを実現できます。

### **4.3. データフローの実現：ParametersとArtifactsの実践**

パイプラインが機能するためには、各ステップがデータを正しく受け渡す必要があります。Argo Workflowsでは、ParametersとArtifactsがこの役割を担います。  
以下の例は、あるステップの出力（処理後のファイルパス）を、次のステップの入力として渡す方法を示しています。
```yaml
#... (workflow definition)  
spec:  
  entrypoint: main-pipeline  
  arguments:  
    parameters:  
    # ワークフロー全体への入力パラメータ  
    - name: input-image-path  
      value: "raw/image-001.jpg"  
  templates:  
  - name: main-pipeline  
    dag:  
      tasks:  
        # --- ステップ1: リサイズ処理 ---  
        - name: resize-step  
          template: resize-container-template  
          arguments:  
            parameters:  
            # ワークフローの入力パラメータを、このステップの入力として渡す  
            - name: input-path  
              value: "{{workflow.parameters.input-image-path}}"

        # --- ステップ2: 物体検出処理 ---  
        - name: object-detection-step  
          # 'resize-step'が完了してから実行する依存関係を定義  
          dependencies: [resize-step]  
          template: object-detection-container-template  
          arguments:  
            parameters:  
            # 前のステップ('resize-step')の出力パラメータ('output-path')を、  
            # このステップの入力として渡す  
            - name: input-path  
              value: "{{tasks.resize-step.outputs.parameters.output-path}}"

  - name: resize-container-template  
    inputs:  
      parameters:  
      - name: input-path  
    outputs:  
      parameters:  
      # このテンプレートが出力するパラメータを定義  
      - name: output-path  
        # 入力パスにサフィックスを付けて、出力パスを生成する  
        value: "{{inputs.parameters.input-path}}-resized"  
    container:  
      #... (container definition)
```

このYAMLのデータフローを分解すると、以下のようになります。

1. ワークフロー実行時に、workflow.parameters.input-image-pathに"raw/image-001.jpg"が設定されます。  
2. resize-stepが開始される際、そのargumentsで{{workflow.parameters.input-image-path}}が評価され、resize-container-templateのinputs.parameters.input-pathに"raw/image-001.jpg"が渡されます。  
3. resize-container-template内では、outputs.parameters.output-pathが{{inputs.parameters.input-path}}-resizedとして定義されています。これにより、このテンプレートの出力は"raw/image-001.jpg-resized"という文字列になります。  
4. resize-stepが完了すると、Argoはtasks.resize-step.outputs.parameters.output-pathという変数に"raw/image-001.jpg-resized"という値を保持します。  
5. object-detection-stepが開始される際、そのargumentsで{{tasks.resize-step.outputs.parameters.output-path}}が評価され、object-detection-container-templateのinputs.parameters.input-pathに"raw/image-001.jpg-resized"が渡されます。

このように、{{...}}構文を駆使することで、各ステップのコンテナは自身が何を受け取り、何を後続に渡すべきかを意識することなく、Argoがオーケストレーションのロジックに従ってデータを自動的に繋ぎ合わせてくれます。これが、疎結合なマイクロサービス間で連携を実現する上で極めて強力なメカニズムです。

## **第5章：パイプラインコンポーネントの構築：マイクロサービスアプローチの実践**

この章では、パイプラインを構成する「部品」となる個々の処理コンテナを、マイクロサービスの原則に従って具体的に実装します。

### **5.1. 指導原則：単一責任の原則 (Single Responsibility Principle)**

マイクロサービスアーキテクチャの根幹をなすのは、「単一責任の原則」です。これは、1つのコンテナ（サービス）は、1つのことだけを行い、それをうまく行うべきだ、という考え方です。この原則に従うことで、以下の利点が生まれます。

* **高い再利用性:** 「リサイズ処理」コンテナは、どんなパイプラインからでも呼び出して利用できます。  
* **容易なメンテナンス:** リサイズ処理のアルゴリズムを改善したい場合、他のコンテナへの影響を一切心配することなく、リサイズ用コンテナだけを修正・デプロイすれば済みます。  
* **独立した技術選択:** リサイズ処理はPythonとOpenCVで、AI処理はC++とTensorFlowで、といったように、各コンポーネントの要件に最適な技術を自由に選択できます。

### **5.2. 実装例1：画像リサイズサービス**

MinIOから画像をダウンロードし、指定されたサイズにリサイズして、結果をMinIOにアップロードするPythonスクリプトを作成します。のサンプルコードをベースに、エラーハンドリング、ロギング、堅牢な引数解析を追加して改良します。  
**services/resize-app/src/resize.py**  
```python
import os  
import sys  
import logging  
import argparse  
from minio import Minio  
import cv2

# ロギング設定  
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():  
    # 引数パーサーの設定  
    parser = argparse.ArgumentParser(description="Resize an image from MinIO.")  
    parser.add_argument("--input-bucket", required=True, help="MinIO bucket for input image")  
    parser.add_argument("--input-path", required=True, help="Path to the input image in the bucket")  
    parser.add_argument("--output-bucket", required=True, help="MinIO bucket for output image")  
    parser.add_argument("--output-path", required=True, help="Path for the output image in the bucket")  
    parser.add_argument("--width", type=int, default=128, help="Target width")  
    parser.add_argument("--height", type=int, default=128, help="Target height")  
    args = parser.parse_args()

    # MinIO接続情報 (環境変数から取得)  
    minio_endpoint = os.getenv("MINIO_ENDPOINT", "minio-service:9000")  
    minio_access_key = os.getenv("MINIO_ACCESS_KEY", "minioadmin")  
    minio_secret_key = os.getenv("MINIO_SECRET_KEY", "minioadmin")

    # ローカルの一時ファイルパス  
    local_input = "/tmp/input_image"  
    local_output = "/tmp/output_image"

    try:  
        # MinIOクライアントの初期化  
        client = Minio(  
            minio_endpoint,  
            access_key=minio_access_key,  
            secret_key=minio_secret_key,  
            secure=False  
        )  
        logging.info(f"Successfully connected to MinIO at {minio_endpoint}")

        # 1. MinIOから画像をダウンロード  
        logging.info(f"Downloading {args.input_path} from bucket {args.input_bucket}...")  
        client.fget_object(args.input_bucket, args.input_path, local_input)  
        logging.info(f"Downloaded to {local_input}")

        # 2. 画像のリサイズ処理 (OpenCVを使用)  
        image = cv2.imread(local_input)  
        if image is None:  
            raise ValueError("Could not read the input image.")  
          
        resized_image = cv2.resize(image, (args.width, args.height))  
        # 元のファイル形式を維持するために拡張子を取得  
        _, ext = os.path.splitext(args.output_path)  
        cv2.imwrite(local_output + ext, resized_image)  
        logging.info(f"Resized image to {args.width}x{args.height} and saved to {local_output + ext}")

        # 3. 処理結果をMinIOにアップロード  
        found = client.bucket_exists(args.output_bucket)  
        if not found:  
            logging.warning(f"Output bucket '{args.output_bucket}' not found. Creating it.")  
            client.make_bucket(args.output_bucket)  
          
        logging.info(f"Uploading {args.output_path} to bucket {args.output_bucket}...")  
        client.fput_object(args.output_bucket, args.output_path, local_output + ext)  
        logging.info("Upload complete.")

    except Exception as e:  
        logging.error(f"An error occurred: {e}")  
        sys.exit(1)

if __name__ == "__main__":  
    main()
```

このスクリプトをコンテナ化するためのDockerfileを作成します。  
**services/resize-app/Dockerfile**  
```
# ベースイメージとして軽量なPythonイメージを選択  
FROM python:3.9-slim

# ワーキングディレクトリを設定  
WORKDIR /app

# 依存ライブラリをインストール  
# opencv-python-headlessはGUI関連のライブラリを含まないため、より軽量  
RUN pip install --no-cache-dir opencv-python-headless minio

# スクリプトをコンテナにコピー  
COPY src/resize.py.

# コンテナ実行時のデフォルトコマンド  
ENTRYPOINT ["python", "resize.py"]
```
### **5.3. 実装例2：AI物体検出サービス**

マイクロサービスアーキテクチャの真価を示すため、リサイズサービスとは全く異なる依存関係を持つAI物体検出サービスを実装します。ここではPyTorchと事前学習済みのYOLOv5モデルを使用します。  
**services/object-detection-app/src/detect.py**
```python
import os  
import sys  
import logging  
import argparse  
from minio import Minio  
import torch  
import cv2

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():  
    parser = argparse.ArgumentParser(description="Detect objects in an image from MinIO using YOLOv5.")  
    parser.add_argument("--input-bucket", required=True)  
    parser.add_argument("--input-path", required=True)  
    parser.add_argument("--output-bucket", required=True)  
    parser.add_argument("--output-path", required=True)  
    args = parser.parse_args()

    minio_endpoint = os.getenv("MINIO_ENDPOINT", "minio-service:9000")  
    minio_access_key = os.getenv("MINIO_ACCESS_KEY", "minioadmin")  
    minio_secret_key = os.getenv("MINIO_SECRET_KEY", "minioadmin")

    local_input = "/tmp/input_image"  
    local_output = "/tmp/output_image"

    try:  
        client = Minio(minio_endpoint, access_key=minio_access_key, secret_key=minio_secret_key, secure=False)  
        logging.info(f"Downloading {args.input_path} from bucket {args.input_bucket}...")  
        client.fget_object(args.input_bucket, args.input_path, local_input)

        # モデルのロード (ローカルにキャッシュされたものを使用)  
        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)  
        logging.info("YOLOv5 model loaded.")

        # 画像の読み込みと推論  
        img = cv2.imread(local_input)  
        results = model(img)

        # 結果の描画  
        results.render() # バウンディングボックスを描画  
        output_img = results.imgs  
          
        _, ext = os.path.splitext(args.output_path)  
        cv2.imwrite(local_output + ext, output_img)  
        logging.info(f"Object detection complete. Result saved to {local_output + ext}")

        # 結果をMinIOにアップロード  
        found = client.bucket_exists(args.output_bucket)  
        if not found:  
            client.make_bucket(args.output_bucket)  
          
        logging.info(f"Uploading {args.output_path} to bucket {args.output_bucket}...")  
        client.fput_object(args.output_bucket, args.output_path, local_output + ext)  
        logging.info("Upload complete.")

    except Exception as e:  
        logging.error(f"An error occurred: {e}")  
        sys.exit(1)

if __name__ == "__main__":  
    main()
```

このAIサービス用のDockerfileは、PyTorchやその他の重いライブラリを含むため、リサイズサービスのものとは大きく異なります。  
**services/object-detection-app/Dockerfile**  
```
FROM python:3.9

WORKDIR /app

# PyTorchなどの重いライブラリをインストール  
# ビルド時間を短縮するため、torchとtorchvisionは個別にインストール  
RUN pip install --no-cache-dir torch torchvision --index-url https://download.pytorch.org/whl/cpu  
RUN pip install --no-cache-dir minio opencv-python-headless ultralytics pandas

COPY src/detect.py.

# 実行時にモデルがダウンロードされるが、ビルド時にキャッシュさせることも可能  
# RUN python -c "import torch; torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"

ENTRYPOINT ["python", "detect.py"]
```
この2つのサービスは、それぞれ全く異なるDockerfileを持ち、互いの依存関係に一切影響を与えません。これがマイクロサービスアーキテクチャの強力な点です。

### **5.4. ビルドとコンテナレジストリへのプッシュ**

作成したコンテナイメージをK3sクラスタから利用できるように、Docker Hubなどのコンテナレジストリにプッシュします。  
# --- リサイズサービスのビルドとプッシュ ---  
# (your-dockerhub-usernameを自身のユーザー名に置き換える)  
```
docker build -t your-dockerhub-username/resize-app:v1./services/resize-app  
docker push your-dockerhub-username/resize-app:v1
```
# --- 物体検出サービスのビルドとプッシュ ---  
```
docker build -t your-dockerhub-username/object-detection-app:v1./services/object-detection-app  
docker push your-dockerhub-username/object-detection-app:v1
```
これで、パイプラインを構成する「部品」の準備が整いました。

## **第6章：総合実装：エンドツーエンドのパイプライン実行**

これまでの章で準備した全ての要素（K3s基盤、コアサービス、処理コンテナ）を組み合わせ、実際に「リサイズ」→「物体検出」というパイプラインをエンドツーエンドで実行します。

### **6.1. 実行前準備**

パイプラインを実行する前に、入力となる画像をMinIOにアップロードしておく必要があります。

1. **MinIO UIにアクセス:** http://\<VM2のIPアドレス\>:30091 にアクセスします。  
2. **バケットの確認:** raw、processed、argo-artifactsの3つのバケットが存在することを確認します。  
3. **画像のアップロード:** rawバケットに、テスト用の画像ファイル（例: test-image.jpg）をアップロードします。

### **6.2. マスターWorkflowマニフェストの作成**

次に、2つの処理コンテナを連携させるためのマスターWorkflow YAMLを作成します。このYAMLが、パイプラインの具体的な「設計図」となります。  
**k8s/workflows/image-processing-pipeline.yaml**  
```
apiVersion: argoproj.io/v1alpha1  
kind: Workflow  
metadata:  
  # ワークフロー名にランダムな接尾辞が付与される  
  generateName: image-processing-pipeline-  
  namespace: argo # argo Namespaceで実行  
spec:  
  # このワークフローの開始地点（エントリーポイント）  
  entrypoint: main-pipeline  
    
  # MinIOをアーティファクトリポジトリとして使用する設定 (第3章で設定済み)  
  artifactRepositoryRef:  
    configMap: argo-artifact-repository-config  
    key: minio

  # ワークフローが受け取る引数  
  arguments:  
    parameters:  
    - name: input-image-path  
      # デフォルトの入力画像パス。実行時に上書き可能。  
      value: "raw/test-image.jpg"

  # --- テンプレートの定義 ---  
  templates:  
  # 1. パイプライン全体の流れを定義するDAGテンプレート  
  - name: main-pipeline  
    dag:  
      tasks:  
        # --- タスク1: リサイズ処理 ---  
        - name: resize-step  
          template: resize-container-template  
          arguments:  
            parameters:  
            - name: input-path  
              value: "{{workflow.parameters.input-image-path}}"  
            - name: output-filename  
              # 出力ファイル名を生成  
              value: "{{workflow.name}}-resized.jpg"

        # --- タスク2: 物体検出処理 ---  
        - name: object-detection-step  
          # resize-stepが完了してから実行  
          dependencies: [resize-step]  
          template: object-detection-container-template  
          arguments:  
            parameters:  
            # 前のステップの出力パスを入力として受け取る  
            - name: input-path  
              value: "{{tasks.resize-step.outputs.parameters.output-path}}"  
            - name: output-filename  
              value: "{{workflow.name}}-detected.jpg"

  # 2. リサイズ処理コンテナのテンプレート  
  - name: resize-container-template  
    inputs:  
      parameters:  
      - name: input-path  
      - name: output-filename  
    outputs:  
      parameters:  
      # このテンプレートの出力パラメータ (次のステップに渡す値)  
      - name: output-path  
        value: "processed/{{inputs.parameters.output-filename}}"  
    container:  
      # 第5章でビルドしたイメージを指定  
      image: your-dockerhub-username/resize-app:v1  
      command: [python, resize.py]  
      args:  
        - "--input-bucket=raw"  
        - "--input-path={{inputs.parameters.input-path}}"  
        - "--output-bucket=processed"  
        - "--output-path={{outputs.parameters.output-path}}"  
        - "--width=640"  
        - "--height=640"  
      env: # MinIOの接続情報を環境変数で渡す  
        - name: MINIO_ENDPOINT  
          value: "minio-service.default.svc.cluster.local:9000"  
        - name: MINIO_ACCESS_KEY  
          value: "minioadmin"  
        - name: MINIO_SECRET_KEY  
          value: "minioadmin"

  # 3. 物体検出コンテナのテンプレート  
  - name: object-detection-container-template  
    inputs:  
      parameters:  
      - name: input-path  
      - name: output-filename  
    outputs:  
      parameters:  
      - name: output-path  
        value: "processed/{{inputs.parameters.output-filename}}"  
    container:  
      image: your-dockerhub-username/object-detection-app:v1  
      command: [python, detect.py]  
      args:  
        - "--input-bucket=processed" # リサイズ後のバケットから読み込む  
        - "--input-path={{inputs.parameters.input-path}}"  
        - "--output-bucket=processed"  
        - "--output-path={{outputs.parameters.output-path}}"  
      env:  
        - name: MINIO_ENDPOINT  
          value: "minio-service.default.svc.cluster.local:9000"  
        - name: MINIO_ACCESS_KEY  
          value: "minioadmin"  
        - name: MINIO_SECRET_KEY  
          value: "minioadmin"
```
### **6.3. パイプラインの実行と監視**

Argo Workflowsには、コマンドラインツールargoが用意されています。これを使ってワークフローをサブミット（実行依頼）し、進行状況を監視します。  
# (未インストールの場合はインストール)  
# brew install argo (macOS) / go install github.com/argoproj/argo-workflows/v3/cmd/argo@latest (その他)

# 作成したワークフロー定義をサブミットし、実行をリアルタイムで監視する  
argo submit --watch -n argo -f k8s/workflows/image-processing-pipeline.yaml

このコマンドは、YAMLファイルをArgoに送信し、ワークフローを開始させます。--watchフラグにより、各ステップの開始、成功、失敗がターミナルにリアルタイムで表示されます。

#### **動的なパラメータの上書き**

Web UIのバックエンドなどからパイプラインを実行する場合、処理対象の画像を動的に変更する必要があります。これは-pオプションで実現できます。  
# 処理対象の画像を変更してパイプラインを実行  
```
argo submit --watch -n argo -f k8s/workflows/image-processing-pipeline.yaml \  
  -p input-image-path="raw/another-test-image.png"
```
この機能が、システムを「動的」にするための鍵となります。バックエンドAPIは、ユーザーのリクエストに応じてこのargo submitコマンドを生成・実行することで、任意のパイプラインをオンデマンドで起動できます。

#### **Argo UIでの監視**

https://localhost:2746 のArgo UIを開くと、実行中のワークフローがDAG（有向非巡回グラフ）としてリアルタイムに可視化されています。

* 実行中のステップは回転するアイコンで表示されます。  
* 成功したステップは緑色のチェックマークに変わります。  
* 失敗したステップは赤色のバツ印に変わります。

各ステップのノードをクリックすると、そのステップ（Pod）の詳細な情報（ログ、入力・出力パラメータ、アーティファクトなど）を確認できます。これは、パイプラインのデバッグやパフォーマンス分析において非常に強力なツールです。

### **6.4. 最終出力の確認**

パイプラインが正常に完了したら、MinIOのprocessedバケットを確認します。そこには、リサイズされた中間画像（例: image-processing-pipeline-xxxx-resized.jpg）と、物体検出の結果がバウンディングボックスとして描画された最終的な画像（例: image-processing-pipeline-xxxx-detected.jpg）が保存されているはずです。

## **第7章：プロジェクトリポジトリの構造とベストプラクティス**

持続可能な開発とチームでの協業を促進するためには、一貫性のあるクリーンなプロジェクト構造が不可欠です。ここでは、本プロジェクトに最適化されたGitHubリポジトリのディレクトリ構造を提案します。

### **7.1. 推奨ディレクトリレイアウト**

以下は、アプリケーションコード、Kubernetesマニフェスト、CI/CDパイプラインを論理的に分離した、スケーラブルなディレクトリ構造です。  
```
image-processing-pipeline/  
├──.github/  
│   └── workflows/  
│       └── ci.yaml             # CI/CDパイプライン定義 (ビルド＆プッシュ)  
├── k8s/  
│   ├── core/  
│   │   ├── minio-deployment.yaml  
│   │   └── minio-pv-pvc.yaml  
│   └── workflows/  
│       └── image-processing-pipeline.yaml  
├── services/  
│   ├── object-detection-app/  
│   │   ├── Dockerfile  
│   │   └── src/  
│   │       └── detect.py  
│   └── resize-app/  
│       ├── Dockerfile  
│       └── src/  
│           └── resize.py  
├──.gitignore  
└── README.md
```
### **7.2. 各ディレクトリの目的と根拠**

この構造は「関心の分離」の原則に基づいています。  
**表5: プロジェクトディレクトリ構造とその役割**

| ディレクトリ            | 目的と根拠                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| :---------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **/.github/workflows/** | **自動化**: GitHub ActionsによるCI/CD（継続的インテグレーション/継続的デプロイメント）のワークフローを定義します。mainブランチへのマージをトリガーに、マイクロサービスのコンテナイメージを自動でビルドし、コンテナレジストリにプッシュする処理を記述します。これにより、手動でのビルド・プッシュ作業が不要になり、ヒューマンエラーを削減できます。                                                                                                                                                      |
| **/k8s/**               | **インフラストラクチャ定義**: 全てのKubernetes関連マニフェスト（YAMLファイル）を格納します。インフラの構成がコードとして一元管理（Infrastructure as Code）され、再現性とバージョン管理が容易になります。\<br\>- **/core/**: MinIOやArgo Workflowsなど、一度デプロイしたら頻繁には変更しない、クラスタのコアとなるサービスの定義を配置します。\<br\>- **/workflows/**: アプリケーション固有のArgo Workflow定義を配置します。パイプラインの種類が増えた場合、ここに新しいYAMLファイルを追加していきます。 |
| **/services/**          | **アプリケーションコード**: 各マイクロサービスのソースコードとDockerfileを格納します。各サービスが独立したサブディレクトリを持つことで、サービス間の結合度が低く保たれ、個別の開発・テスト・デプロイが容易になります。新しいサービスを追加する際は、ここに新しいディレクトリを作成するだけです。                                                                                                                                                                                                        |

### **7.3. CI/CDによる自動化への道筋**

将来的な開発効率の向上のため、CI/CDパイプラインの導入を強く推奨します。以下は、GitHub Actionsを使用したCIパイプラインの簡単な例です。このファイルを/.github/workflows/ci.yamlとして保存すると、services/ディレクトリ内のコードが変更されてmainブランチにプッシュされた際に、自動でDockerイメージのビルドとプッシュが実行されます。  
**.github/workflows/ci.yaml**  
```
name: Build and Push Docker Images

on:  
  push:  
    branches: [ "main" ]  
    paths:  
      - 'services/**'

env:  
  DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}  
  DOCKER_REPO: your-dockerhub-username

jobs:  
  build-and-push:  
    runs-on: ubuntu-latest  
    strategy:  
      matrix:  
        service: [resize-app, object-detection-app]  
    steps:  
      - name: Checkout repository  
        uses: actions/checkout@v3

      - name: Log in to Docker Hub  
        uses: docker/login-action@v2  
        with:  
          username: ${{ secrets.DOCKER_USERNAME }}  
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker image  
        uses: docker/build-push-action@v4  
        with:  
          context:./services/${{ matrix.service }}  
          push: true  
          tags: ${{ env.DOCKER_REPO }}/${{ matrix.service }}:latest
```
（※このワークフローを実行するには、GitHubリポジトリのSettings \> Secrets and variables \> ActionsでDOCKER\_USERNAMEとDOCKER\_PASSWORDを登録する必要があります。）  
このような自動化を導入することで、開発チームはコードの品質向上に集中でき、デプロイプロセス全体の信頼性と速度が向上します。

## **第8章：運用の高度化と将来の成長**

初期実装が完了した後、システムの運用を安定させ、将来の要求に対応していくための指針を示します。

### **8.1. システムのスケーリング**

本アーキテクチャは、スケーラビリティを念頭に設計されています。負荷が増大した場合、以下の方法でシステムを拡張できます。

#### **8.1.1. ワーカーノードの追加によるスケールアウト**

現在、K3sは単一のサーバーノードで動作していますが、処理能力が不足してきた場合は、新しいVMをクラスタに「エージェント（ワーカー）ノード」として追加できます。

1. **サーバーノードでトークンを確認:** 既存のサーバーノード（VM2）で以下のコマンドを実行し、エージェントが接続するためのトークンを取得します。  
   sudo cat /var/lib/rancher/k3s/server/node-token

2. **エージェントノードでインストール:** 新しいVM（例: VM3）で、以下のコマンドを実行します。YOUR_SERVER_IPとYOUR_TOKENを実際のものに置き換えてください。  
```
   curl -sfL https://get.k3s.io | K3S_URL=https://<YOUR_SERVER_IP>:6443 K3S_TOKEN=<YOUR_TOKEN> sh -
```
これでVM3がクラスタに追加され、K3sは自動的に新しいノードにもPodをスケジュールするようになります。kubectl get nodesを実行すると、新しいノードが表示されるはずです。

#### **8.1.2. 異種混合クラスタとGPUの活用**

将来的に、高性能なGPUを搭載したサーバーを導入する場合、AI処理のような計算負荷の高いタスクをその専用ノードで実行させることが、コスト効率の観点から非常に重要です。これはKubernetesのnodeSelectorという機能で実現できます。

1. **ノードにラベルを付ける:** GPUを搭載した新しいノード（例: gpu-node-1）に、特別なラベルを付けます。  
   ```
   kubectl label node gpu-node-1 hardware=gpu
   ```
2. **Workflow定義を修正:** 物体検出コンテナのテンプレートにnodeSelectorを追加します。  
   ```
   #... (object-detection-container-template)  
   container:  
     #... (image, command, args, env)  
   # このPodは 'hardware=gpu' というラベルを持つノードにのみスケジュールされる  
   nodeSelector:  
     hardware: gpu
   ```
このように設定することで、物体検出Podは必ずGPU搭載ノードで実行され、リサイズ処理のようなCPUバウンドなPodは他の汎用ノードで実行されるようになります。これにより、高価なGPUリソースを最大限に有効活用できます。これは、モノリスアーキテクチャでは実現不可能な、マイクロサービスアーキテクチャの大きな利点の一つです。

### **8.2. 監視とオブザーバビリティ**

安定したシステム運用には、各コンポーネントの状態を監視し、問題の予兆を早期に検知する「オブザーバビリティ（可観測性）」が不可欠です。Kubernetesエコシステムには、このためのデファクトスタンダードなツール群が存在します。

* **メトリクス監視 (Prometheus & Grafana):** Prometheusは、クラスタ内の各コンポーネント（ノード、Podなど）のリソース使用率（CPU, メモリ）や、アプリケーション固有のメトリクス（例: パイプラインの処理時間）を収集する時系列データベースです。Grafanaは、Prometheusが収集したデータを可視化し、美しいダッシュボードを作成するためのツールです。  
* **ログ集約 (Fluentd & Loki):** FluentdやLokiといったツールを導入することで、クラスタ内で実行されている全てのコンテナのログを一元的に収集し、検索・分析することが可能になります。

これらのツールはKubernetesとネイティブに連携するように設計されており、「Prometheus Operator」や「Loki Stack」といったパッケージを使えば、比較的容易にクラスタに導入できます。

### **8.3. 結論：クラウドネイティブの旅へ**

本レポートでは、K3sとArgo Workflowsを中核とした、動的でスケーラブルな画像処理パイプラインの設計から実装、運用までの全工程を詳細に解説しました。  
選択されたマイクロサービスアーキテクチャは、一見すると構成要素が多く複雑に感じられるかもしれません。また、Kubernetes未経験のチームにとっては、初期の学習コストが伴うことも事実です。しかし、その初期投資を乗り越えることで得られる恩恵は計り知れません。

* **究極の柔軟性:** 新しいAIモデルや処理コンポーネントを、既存システムに影響を与えることなく安全に追加・交換できます。  
* **効率的なスケーラビリティ:** システムのボトルネックとなっている箇所だけを独立してスケールさせ、リソースを無駄なく活用できます。  
* **高い耐障害性とメンテナンス性:** 各コンポーネントが独立しているため、障害の影響範囲が限定され、修正も容易です。  
* **ポータブルなスキルセット:** ここで習得するKubernetesの知識とスキルは、特定のベンダーに依存しない、業界標準のポータブルな資産となります。

このアーキテクチャは、単に目先の要件を満たすだけでなく、将来のビジネスの成長や技術の進化に柔軟に対応し続けるための、堅牢で合理的な基盤を提供します。このガイドが、貴チームのクラウドネイティブへの旅路における、信頼できる羅針盤となることを確信しています。
