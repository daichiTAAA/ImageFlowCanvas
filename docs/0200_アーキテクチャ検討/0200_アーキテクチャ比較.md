# アーキテクチャ比較

## **第1章：動的クラウドネイティブパイプラインのアーキテクチャ設計**

### **1.1. 中核となる課題と戦略的解決策**

本プロジェクトが解決すべき中核的な課題は、「Web画面から、前処理、AI処理、後処理といった『部品』を自由に組み合わせ、動的なパイプラインを構築したい」という高度な要求にあります。この要件は、単にコンテナを実行するだけでなく、処理フローの制御、データの受け渡し、スケーラビリティ、そして特定のクラウドベンダーにロックインされないポータビリティを実現できるアーキテクチャを必要とします。

これらの課題に対する解決策として、**2つの主要なアプローチ**が考えられます：

#### **アプローチ1: 処理毎コンテナ分離アーキテクチャ**
**最大の柔軟性と拡張性を実現する本格的なマイクロサービス構成**

1. **コンテナオーケストレーション基盤 (K3s):** 軽量でありながら完全なKubernetes互換性を持つ基盤。各処理コンテナのライフサイクル管理を担います。
2. **ワークフローエンジン (Argo Workflows):** Web UIから選択された処理部品を動的にDAG（有向非環グラフ）として構築・実行する「指揮者」の役割。
3. **共有オブジェクトストレージ (MinIO):** 処理間のデータ受け渡しを担う中間ストレージ。各処理コンポーネントを疎結合に保ちます。
4. **マイクロサービス化された処理コンテナ:** 「リサイズ処理」「物体検出AI」「後処理」等を独立したコンテナとして実装。

**メリット:** 真の動的パイプライン構築、きめ細かいスケーリング、完全な障害分離  
**デメリット:** 学習・運用コストが高い、処理遅延がやや大きい

#### **アプローチ2: 統合コンテナ + Triton APIアーキテクチャ**
**運用の簡潔性と処理性能を重視したプラグマティック構成**

1. **コンテナオーケストレーション基盤 (Nomad/Docker Compose):** シンプルなジョブスケジューラによる統合コンテナの管理。
2. **統合処理コンテナ:** 前処理から後処理までを単一コンテナ内で実行。ストラテジーパターンにより複数のフローを同一イメージから実行可能。
3. **Triton Inference Server:** AI推論処理のみを外部化し、REST API経由で利用。
4. **軽量サービスディスカバリ (Consul):** シンプルな構成管理と監視。

**メリット:** 学習・運用コストが低い、処理遅延が最小、短期間での導入が可能  
**デメリット:** 動的パイプライン構築の柔軟性が制限される、新処理追加時は全体再ビルドが必要

#### **選択指針**
どちらのアプローチも有効であり、**プロジェクトの要件、チームのスキルレベル、運用体制によって最適解は変わります。** 以下のセクションでは、両アプローチの特性を詳細に分析し、適切な選択を支援する情報を提供します。

### **1.2. マイクロサービス設計パターンの比較検討**

次に、マイクロサービスアーキテクチャ内での具体的な設計パターンを比較検討します。具体的には、「各処理を独立したコンテナに分離するアプローチ」と「画像の取得から結果の送付まで1つのコンテナで処理し、AI推論のみTriton Inference ServerにREST API経由で実施するアプローチ」です。  
どちらのアプローチにもそれぞれ明確な利点があり、プロジェクトの要件、チームのスキルレベル、運用体制によって最適解は変わります。両者の特性を詳細に分析し、適切な選択を支援します。

**統合コンテナ + Triton APIアプローチの主要な利点：**

1. **学習・運用コストの大幅削減:** このアプローチでは、**K3sやArgo Workflowsのような複雑なオーケストレーション技術が不要**です。DockerとDocker Composeの知識があれば十分であり、Kubernetesの学習コストを完全に回避できます。チーム全体での技術習得期間を数ヶ月から数週間に短縮でき、即座にプロダクション運用を開始可能です。

2. **処理遅延の最小化:** **コンテナ間のデータ受け渡しが不要**なため、画像データをメモリ上で直接処理でき、ディスクI/Oやネットワーク通信のオーバーヘッドを完全に排除できます。特に高解像度画像やリアルタイム処理において、数百ミリ秒から数秒の遅延短縮効果が期待できます。

3. **運用の簡潔性:** 単一のコンテナログを監視すれば全体の動作状況を把握でき、デバッグも容易です。分散システム特有の「どのコンポーネントで問題が発生しているか特定困難」という課題を回避できます。

**処理毎コンテナ分離アプローチの主要な利点：**

1. **動的パイプライン構築の柔軟性:** Argo Workflowsにより、Web UIから部品を選択して任意の組み合わせでパイプラインを構築できる真の動的システムを実現できます。

2. **きめ細かいスケーリング:** ボトルネックとなる処理のみを選択的にスケールでき、リソース効率を最大化できます。

3. **完全な障害分離:** 一つの処理の障害が他に波及しない高い信頼性を実現できます。

**表2: マイクロサービス設計パターン比較**

| 評価項目             | アプローチ1：処理毎コンテナ分離                                                                                    | アプローチ2：統合コンテナ + Triton API                                                                             |
| :------------------- | :----------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| **学習コスト**       | △ **高い**。K3s、Argo Workflowsの習得が必要。チーム全体で数ヶ月の学習期間を要する。                                | ◎ **非常に低い**。DockerとDocker Composeの知識で十分。既存スキルで即座に開発開始可能。                             |
| **運用コスト**       | △ **やや高い**。分散システムの監視・デバッグには専門知識が必要。複数コンポーネントの連携状況を把握する必要がある。 | ◎ **低い**。単一コンテナの監視とログ分析で十分。従来のモノリシックアプリケーションと同様の運用手法を適用可能。     |
| **処理遅延**         | △ **やや高い**。コンテナ間のデータ受け渡しでディスクI/Oやネットワーク通信のオーバーヘッドが発生。                  | ◎ **最小**。画像データをメモリ上で連続処理するため、データ転送のオーバーヘッドが皆無。リアルタイム処理に最適。     |
| **柔軟性・拡張性**   | ◎ **非常に高い**。各処理が独立した「部品」として機能し、Argo Workflowsで任意の組み合わせとフローを動的に構築可能。 | ○ **高い**。ストラテジーパターンにより同一イメージから複数フローを実行可能。ただし新処理追加時は全体再ビルド。     |
| **開発・保守性**     | ◎ **優秀**。各処理を独立して開発・テスト・デプロイ可能。処理の変更が他に影響しない。                               | ○ **良好**。単一コード基盤での開発により、チーム間の連携コストが低い。ただし変更影響範囲の分析が必要。             |
| **スケーラビリティ** | ◎ **最適**。ボトルネックとなる処理のみを選択的にスケール可能。リソース効率が最大化される。                         | ○ **良好**。パイプライン毎のコンテナ分離により、各パイプラインの特性に応じたスケーリングが可能。                   |
| **障害分離**         | ◎ **完全分離**。各処理の障害が他の処理に波及しない。部分的な障害でもパイプライン全体の継続性を維持。               | ○ **パイプライン単位で分離**。パイプライン間の障害分離は可能だが、パイプライン内の処理間では障害が波及する可能性。 |
| **導入速度**         | △ **数ヶ月**。基盤技術の学習とセットアップに時間を要する。                                                         | ◎ **数週間**。既存技術で即座に開発開始でき、短期間でのMVP構築が可能。                                              |

### **1.3. アプローチ別オーケストレーション戦略**

コンテナオーケストレーション基盤の選定は、前節で検討した２つのアプローチによって最適解が大きく異なります。ここでは、各アプローチの特性を踏まえた最適なオーケストレーション戦略を提示します。

#### **1.3.1. アプローチ1（処理毎コンテナ分離）: K3s + Argo Workflows**

**アプローチ1では、K3sが必須となります。** その理由は、動的パイプライン構築という核心要件を実現するために、Argo Workflowsの強力なワークフロー制御機能が不可欠だからです。

**なぜK3sが必要か：**
- **Argo Workflowsとの完全互換性**: Argo WorkflowsはKubernetesのAPIとリソース（Pod, ServiceAccount, Custom Resource Definitions）を深く利用して設計されており、K3sの100% Kubernetes互換APIが必要
- **動的パイプライン実現**: 処理コンテナ間の複雑な依存関係、実行順序、データフローをYAMLテンプレートで柔軟に定義可能
- **部品化された処理の組み合わせ**: Web UIから選択された処理部品を、Argo Workflowsが動的にDAG（有向非環グラフ）として構築・実行

**技術スタック：**
```
K3s (軽量Kubernetes)
├── Argo Workflows (パイプライン制御)
├── MinIO (共有ストレージ)
└── 処理コンテナ群 (各処理を独立コンテナ化)
```

#### **1.3.2. アプローチ2（統合コンテナ + Triton API）: Nomad推奨**

**アプローチ2では、Nomadが最適解となります。** このアプローチでは複雑なワークフロー制御は不要で、むしろNomadのシンプルさと運用の容易さが大きなメリットをもたらします。

**なぜNomadが最適か：**
- **単純なジョブスケジューリング**: 統合コンテナの起動・停止・スケーリングのみで十分。複雑なワークフロー制御は不要
- **運用コストの最小化**: HashiCorp製品群（Consul, Vault）との自然な連携により、シンプルな運用環境を構築可能
- **学習コストの削減**: Kubernetesの概念（Pod, Service, Deployment等）を習得する必要がなく、より直感的な運用が可能

**技術スタック：**
```
Nomad (ジョブスケジューラ)
├── Consul (サービスディスカバリ)
├── Triton Inference Server (AI推論)
└── 統合処理コンテナ (全処理を内包)
```

#### **1.3.3. アプローチ別比較表**

**表3: アプローチ別オーケストレーション比較**

| 評価項目             | アプローチ1: K3s + Argo Workflows                                                                                | アプローチ2: Nomad + Consul                                                                           |
| :------------------- | :--------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------- |
| **ワークフロー制御** | ◎ **必須かつ最適**。動的パイプライン構築に不可欠なArgo Workflowsの機能をフル活用。                               | ○ **不要だが対応可能**。単純なジョブ実行のため、Nomadの基本機能で十分。                               |
| **運用複雑度**       | △ **やや複雑**。K3s、Argo Workflows、MinIOの連携運用が必要。分散システムの監視・デバッグスキルが求められる。     | ◎ **非常にシンプル**。NomadとConsulの組み合わせは直感的。従来のサーバー運用の延長で管理可能。         |
| **学習コスト**       | △ **高い**。Kubernetes概念（Pod、Service等）とArgo Workflowsの習得が必要。チーム全体で数ヶ月の学習期間を要する。 | ◎ **低い**。Nomadジョブファイルの記法は直感的。既存のインフラスキルで対応可能。                       |
| **柔軟性**           | ◎ **最大**。任意の処理組み合わせを動的に構築可能。新しい処理部品の追加が容易。                                   | ○ **制限あり**。統合コンテナ内の処理フロー変更は全体再ビルドが必要。                                  |
| **スケーラビリティ** | ◎ **きめ細かい**。ボトルネック処理のみを選択的にスケール可能。リソース効率が最大化される。                       | ○ **パイプライン単位**。パイプライン全体をスケールするため、一部リソースの無駄が発生する可能性。      |
| **エコシステム**     | ◎ **豊富**。CNCF製品群との連携により、監視・ロギング・セキュリティ等の高度な運用機能を容易に導入可能。           | ○ **HashiCorp中心**。Vault、Consul、Terraformとの連携は強力だが、サードパーティ製品との連携は限定的。 |
| **適用シナリオ**     | 動的パイプライン構築が必須。処理部品の頻繁な追加・変更が想定される。長期的な拡張性を重視。                       | シンプルな運用を最優先。処理フローが比較的固定的。短期間でのシステム立ち上げを重視。                  |

#### **1.3.4. 推奨選択指針**

**アプローチ1（K3s）を選択すべき場合：**
- Web UIからの動的パイプライン構築が絶対要件
- 処理部品の追加・変更が頻繁に発生する見込み
- チームにKubernetes経験者がいる、または学習時間を確保できる
- 長期的なシステム拡張性を重視

**アプローチ2（Nomad）を選択すべき場合：**
- 運用の簡潔性を最優先する
- 短期間でのシステム立ち上げが必要
- チームの技術スキルを既存範囲内に留めたい
- 処理フローが比較的固定的で、動的な変更頻度が低い