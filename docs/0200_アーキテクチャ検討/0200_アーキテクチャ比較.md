# アーキテクチャ比較

## **第1章：動的パイプラインのアーキテクチャ設計**

### **1.1. 中核となる課題と戦略的解決策**

本プロジェクトが解決すべき中核的な課題は、「Web画面から、前処理、AI処理、後処理といった『部品』を自由に組み合わせ、動的なパイプラインを構築したい」という高度な要求にあります。この要件は、単にコンテナを実行するだけでなく、処理フローの制御、データの受け渡し、スケーラビリティ、そして特定のクラウドベンダーにロックインされないポータビリティを実現できるアーキテクチャを必要とします。

これらの課題に対する解決策として、**2つの主要なアプローチ**が考えられます：

#### **アプローチ1: 直接gRPC呼び出し + 常駐サービスアーキテクチャ**
**超高速処理性能とシンプルな動的パイプライン構築を両立する最適化構成**

1. **コンテナオーケストレーション基盤 (K3s):** Kubernetesベースの軽量で安定した基盤。gRPC常駐サービスの継続運用を管理。
2. **直接gRPC呼び出しパターン:** バックエンドAPIから常駐gRPCサービス群への直接呼び出し。40-100msの超高速処理を実現。
3. **gRPCマイクロサービス化された常駐処理群:** 各処理機能（リサイズ、AI検知、フィルタ）をProtocol Buffersベースの高性能gRPCサービスとして設計・実装。
4. **Triton Inference Server (gRPC):** AI推論専用サーバーのネイティブgRPCインターフェースによる最高性能モデル管理と推論処理。
5. **分散オブジェクトストレージ (MinIO):** 画像データとメタデータの効率的な永続化・共有。
6. **動的パイプライン制御ロジック:** バックエンドAPI内でパイプライン構成を解析し、適切なgRPCサービス呼び出し順序を動的に決定。
7. **Protocol Buffers Schema:** 型安全で高性能なデータ交換とバージョニング管理。

**メリット:** 超高速処理（40-100ms）、動的パイプライン構築、型安全性、運用シンプル化、即座のレスポンス  
**デメリット:** 複雑なパイプラインでのエラーハンドリング設計が必要、バックエンドAPIの責任範囲拡大

#### **アプローチ2: 統合コンテナ + Triton APIアーキテクチャ**
**運用の簡潔性と処理性能を重視したプラグマティック構成**

1. **コンテナオーケストレーション基盤 (Nomad/Docker Compose):** シンプルなジョブスケジューラによる統合コンテナの管理。
2. **統合処理コンテナ:** 前処理から後処理までを単一コンテナ内で実行。ストラテジーパターンにより複数のフローを同一イメージから実行可能。
3. **Triton Inference Server:** AI推論処理のみを外部化し、REST API経由で利用。
4. **軽量サービスディスカバリ (Consul):** シンプルな構成管理と監視。

**メリット:** 学習・運用コストが低い、処理遅延が最小、短期間での導入が可能  
**デメリット:** 動的パイプライン構築の柔軟性が制限される、新処理追加時は全体再ビルドが必要

#### **選択指針**
どちらのアプローチも有効であり、**プロジェクトの要件、チームのスキルレベル、運用体制によって最適解は変わります。** 以下のセクションでは、両アプローチの特性を詳細に分析し、適切な選択を支援する情報を提供します。

### **1.2. マイクロサービス設計パターンの比較検討**

次に、マイクロサービスアーキテクチャ内での具体的な設計パターンを比較検討します。具体的には、「各処理を独立したコンテナに分離するアプローチ」と「画像の取得から結果の送付まで1つのコンテナで処理し、AI推論のみTriton Inference ServerにREST API経由で実施するアプローチ」です。  
どちらのアプローチにもそれぞれ明確な利点があり、プロジェクトの要件、チームのスキルレベル、運用体制によって最適解は変わります。両者の特性を詳細に分析し、適切な選択を支援します。

**統合コンテナ + Triton APIアプローチの主要な利点：**

1. **学習・運用コストの大幅削減:** このアプローチでは、**K3sのような複雑なオーケストレーション技術が不要**です。DockerとDocker Composeの知識があれば十分であり、Kubernetesの学習コストを完全に回避できます。チーム全体での技術習得期間を数ヶ月から数週間に短縮でき、即座にプロダクション運用を開始可能です。

2. **処理遅延の最小化:** **コンテナ間のデータ受け渡しが不要**なため、画像データをメモリ上で直接処理でき、ディスクI/Oやネットワーク通信のオーバーヘッドを完全に排除できます。特に高解像度画像やリアルタイム処理において、数百ミリ秒から数秒の遅延短縮効果が期待できます。

3. **運用の簡潔性:** 単一のコンテナログを監視すれば全体の動作状況を把握でき、デバッグも容易です。分散システム特有の「どのコンポーネントで問題が発生しているか特定困難」という課題を回避できます。

**処理毎コンテナ分離アプローチの主要な利点：**

1. **動的パイプライン構築の柔軟性:** 直接gRPC呼び出しにより、Web UIから部品を選択して任意の組み合わせでパイプラインを構築できる真の動的システムを実現できます。

2. **きめ細かいスケーリング:** ボトルネックとなる処理のみを選択的にスケールでき、リソース効率を最大化できます。

3. **完全な障害分離:** 一つの処理の障害が他に波及しない高い信頼性を実現できます。

**表2: マイクロサービス設計パターン比較**

| 評価項目             | アプローチ1：処理毎コンテナ分離                                                                                    | アプローチ2：統合コンテナ + Triton API                                                                             |
| :------------------- | :----------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------- |
| **学習コスト**       | △ **高い**。K3sの習得が必要。チーム全体で数ヶ月の学習期間を要する。                                                | ◎ **非常に低い**。DockerとDocker Composeの知識で十分。既存スキルで即座に開発開始可能。                             |
| **運用コスト**       | △ **やや高い**。分散システムの監視・デバッグには専門知識が必要。複数コンポーネントの連携状況を把握する必要がある。 | ◎ **低い**。単一コンテナの監視とログ分析で十分。従来のモノリシックアプリケーションと同様の運用手法を適用可能。     |
| **処理遅延**         | △ **やや高い**。コンテナ間のデータ受け渡しでディスクI/Oやネットワーク通信のオーバーヘッドが発生。                  | ◎ **最小**。画像データをメモリ上で連続処理するため、データ転送のオーバーヘッドが皆無。リアルタイム処理に最適。     |
| **柔軟性・拡張性**   | ◎ **非常に高い**。各処理が独立した「部品」として機能し、任意の組み合わせとフローを動的に構築可能。                 | ○ **高い**。ストラテジーパターンにより同一イメージから複数フローを実行可能。ただし新処理追加時は全体再ビルド。     |
| **開発・保守性**     | ◎ **優秀**。各処理を独立して開発・テスト・デプロイ可能。処理の変更が他に影響しない。                               | ○ **良好**。単一コード基盤での開発により、チーム間の連携コストが低い。ただし変更影響範囲の分析が必要。             |
| **スケーラビリティ** | ◎ **最適**。ボトルネックとなる処理のみを選択的にスケール可能。リソース効率が最大化される。                         | ○ **良好**。パイプライン毎のコンテナ分離により、各パイプラインの特性に応じたスケーリングが可能。                   |
| **障害分離**         | ◎ **完全分離**。各処理の障害が他の処理に波及しない。部分的な障害でもパイプライン全体の継続性を維持。               | ○ **パイプライン単位で分離**。パイプライン間の障害分離は可能だが、パイプライン内の処理間では障害が波及する可能性。 |
| **導入速度**         | △ **数ヶ月**。基盤技術の学習とセットアップに時間を要する。                                                         | ◎ **数週間**。既存技術で即座に開発開始でき、短期間でのMVP構築が可能。                                              |

### **1.3. アプローチ別オーケストレーション戦略**

コンテナオーケストレーション基盤の選定は、前節で検討した２つのアプローチによって最適解が大きく異なります。ここでは、各アプローチの特性を踏まえた最適なオーケストレーション戦略を提示します。

#### **1.3.1. アプローチ1（直接gRPC呼び出し）: K3s + gRPC常駐サービス**

**アプローチ1では、K3sとgRPC常駐サービスが核となります。** 超高速処理を実現するための最適化されたアーキテクチャです。

**なぜ直接gRPC呼び出しが最適か：**
- **最小限のレイテンシ**: 40-100msの処理時間を実現
- **動的パイプライン制御**: バックエンドAPI内でパイプライン構成を解析し、適切なgRPCサービス呼び出し順序を動的決定
- **常駐サービスの活用**: 事前起動されたgRPCサービス群への即座の処理要求により、コンテナ起動時間を排除

**技術スタック：**
```
K3s (軽量Kubernetes)
├── gRPC常駐サービス群 (リサイズ、AI検知、フィルタ)
├── バックエンドAPI (パイプライン制御ロジック)
├── MinIO (共有ストレージ)
└── Triton Inference Server (AI推論)
```

#### **1.3.2. アプローチ2（統合コンテナ + Triton API）: Nomad推奨**

**アプローチ2では、Nomadが最適解となります。** このアプローチでは複雑なワークフロー制御は不要で、むしろNomadのシンプルさと運用の容易さが大きなメリットをもたらします。

**なぜNomadが最適か：**
- **単純なジョブスケジューリング**: 統合コンテナの起動・停止・スケーリングのみで十分。複雑なワークフロー制御は不要
- **運用コストの最小化**: HashiCorp製品群（Consul, Vault）との自然な連携により、シンプルな運用環境を構築可能
- **学習コストの削減**: Kubernetesの概念（Pod, Service, Deployment等）を習得する必要がなく、より直感的な運用が可能

**技術スタック：**
```
Nomad (ジョブスケジューラ)
├── Consul (サービスディスカバリ)
├── Triton Inference Server (AI推論)
└── 統合処理コンテナ (全処理を内包)
```

#### **1.3.3. アプローチ別比較表**

**表3: アプローチ別オーケストレーション比較**

| 評価項目             | アプローチ1: K3s + 直接gRPC呼び出し                                                                    | アプローチ2: Nomad + Consul                                                                           |
| :------------------- | :----------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------- |
| **処理速度**         | ◎ **超高速**。40-100msの処理時間を実現。                                                               | ○ **高速**。統合コンテナ内での処理により中間データ転送を排除。                                        |
| **運用複雑度**       | ○ **適度**。K3sとgRPCサービス群の管理。                                                                | ◎ **非常にシンプル**。NomadとConsulの組み合わせは直感的。従来のサーバー運用の延長で管理可能。         |
| **学習コスト**       | ○ **中程度**。K3s基本知識とgRPC理解が必要。                                                            | ◎ **低い**。Nomadジョブファイルの記法は直感的。既存のインフラスキルで対応可能。                       |
| **柔軟性**           | ◎ **最大**。バックエンドAPIで動的パイプライン制御。新処理追加が容易。                                  | ○ **制限あり**。統合コンテナ内の処理フロー変更は全体再ビルドが必要。                                  |
| **スケーラビリティ** | ◎ **きめ細かい**。ボトルネック処理のみを選択的にスケール可能。リソース効率が最大化される。             | ○ **パイプライン単位**。パイプライン全体をスケールするため、一部リソースの無駄が発生する可能性。      |
| **エコシステム**     | ◎ **豊富**。CNCF製品群との連携により、監視・ロギング・セキュリティ等の高度な運用機能を容易に導入可能。 | ○ **HashiCorp中心**。Vault、Consul、Terraformとの連携は強力だが、サードパーティ製品との連携は限定的。 |
| **適用シナリオ**     | 超高速処理が必要。動的パイプライン構築が必須。リアルタイム性を重視。                                   | シンプルな運用を最優先。処理フローが比較的固定的。短期間でのシステム立ち上げを重視。                  |

#### **1.3.4. 推奨選択指針**

**アプローチ1（直接gRPC呼び出し）を選択すべき場合：**
- 超高速処理（40-100ms）が絶対要件
- Web UIからの動的パイプライン構築が必要
- リアルタイム性を重視するアプリケーション
- 処理部品の追加・変更が頻繁に発生する見込み
- 長期的なシステム拡張性を重視

**アプローチ2（Nomad）を選択すべき場合：**
- 運用の簡潔性を最優先する
- 短期間でのシステム立ち上げが必要
- チームの技術スキルを既存範囲内に留めたい
- 処理フローが比較的固定的で、動的な変更頻度が低い
